{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read data from text files\n",
    "with open('data/reviews.txt', 'r') as f:\n",
    "    reviews = f.read()\n",
    "with open('data/labels.txt', 'r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \n",
      "story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turn\n",
      "\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "ne\n"
     ]
    }
   ],
   "source": [
    "print(reviews[:1000])\n",
    "print()\n",
    "print(labels[:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "print(punctuation)\n",
    "\n",
    "# Delete all punctuation\n",
    "reviews = reviews.lower() # transform to lowercase\n",
    "all_text = ''.join([c for c in reviews if c not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the reviews\n",
    "reviews_split = all_text.split('\\n')\n",
    "\n",
    "# Join them to create one text\n",
    "all_text = ' '.join(reviews_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all words\n",
    "words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6020196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bromwell',\n",
       " 'high',\n",
       " 'is',\n",
       " 'a',\n",
       " 'cartoon',\n",
       " 'comedy',\n",
       " 'it',\n",
       " 'ran',\n",
       " 'at',\n",
       " 'the',\n",
       " 'same',\n",
       " 'time',\n",
       " 'as',\n",
       " 'some',\n",
       " 'other',\n",
       " 'programs',\n",
       " 'about',\n",
       " 'school',\n",
       " 'life',\n",
       " 'such',\n",
       " 'as',\n",
       " 'teachers',\n",
       " 'my',\n",
       " 'years',\n",
       " 'in',\n",
       " 'the',\n",
       " 'teaching',\n",
       " 'profession',\n",
       " 'lead',\n",
       " 'me']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(words))\n",
    "words[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "Encode the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import tqdm\n",
    "\n",
    "vocab_to_int = dict()\n",
    "\n",
    "reviews_ints = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74072\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "\n",
    "for word in words:\n",
    "    counter[word] += 1\n",
    "    \n",
    "unique_words = list(counter)\n",
    "print(len(unique_words)) # shoulde be more 74000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74073\n"
     ]
    }
   ],
   "source": [
    "vocab_to_int['\\n'] = 0\n",
    "\n",
    "for i, word in enumerate(unique_words):\n",
    "    vocab_to_int[word] = i + 1 # 0 is reserved for \"\\n\"\n",
    "    \n",
    "print(len(vocab_to_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell high is a cartoon comedy  it ran at the same time as some other programs about school life  such as  teachers   my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers   the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students  when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled          at           high  a classic line inspector i  m here to sack one of your teachers  student welcome to bromwell high  i expect that many adults of my age think that bromwell high is far fetched  what a pity that it isn  t   ',\n",
       " 'story of a man who has unnatural feelings for a pig  starts out with a opening scene that is a terrific example of absurd comedy  a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers  unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting  even those from the era should be turned off  the cryptic dialogue would make shakespeare seem easy to a third grader  on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond  future stars sally kirkland and frederic forrest can be seen briefly   ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_split[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in reviews_split:\n",
    "    \n",
    "    encoded_review = list()\n",
    "    \n",
    "    for word in review.split():\n",
    "        \n",
    "        idx = vocab_to_int[word]\n",
    "        encoded_review.append(idx)\n",
    "        \n",
    "    reviews_ints.append(encoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words:  74073\n",
      "\n",
      "Tokenized review: \n",
      " [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 13, 21, 22, 23, 24, 10, 25, 26, 27, 28, 29, 30, 31, 1, 2, 32, 33, 3, 34, 35, 29, 36, 37, 3, 21, 10, 38, 29, 39, 40, 10, 41, 42, 43, 44, 45, 46, 47, 48, 49, 21, 50, 10, 51, 52, 10, 53, 54, 55, 56, 28, 52, 10, 57, 58, 59, 60, 48, 42, 61, 58, 62, 10, 63, 24, 64, 4, 65, 66, 67, 29, 68, 69, 10, 18, 58, 70, 71, 9, 2, 4, 72, 73, 74, 58, 75, 76, 29, 77, 78, 52, 79, 21, 65, 80, 29, 1, 2, 58, 81, 31, 82, 83, 52, 22, 84, 85, 31, 1, 2, 3, 86, 87, 88, 4, 89, 31, 7, 90, 91]]\n"
     ]
    }
   ],
   "source": [
    "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
    "print()\n",
    "\n",
    "print('Tokenized review: \\n', reviews_ints[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "Encode the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label in labels.split('\\n'):\n",
    "    \n",
    "    encoded_labels.append(1 if label == 'positive' else 0)\n",
    "    \n",
    "encoded_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3  \n",
    "Delete outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save copies\n",
    "orig_reviews_ints = reviews_ints.copy()\n",
    "orig_encoded_labels = encoded_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140, 114]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: len(x)\n",
    "lengths = list(map(f, reviews_ints))\n",
    "lengths[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length: 240.79820807167712\n"
     ]
    }
   ],
   "source": [
    "print('Mean length:', np.mean(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all reviews that are shorter than 1% percentile, and longer than 99% percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1% percentile: 43.0\n",
      "99% percentile: 935.0\n"
     ]
    }
   ],
   "source": [
    "perc_1 = np.percentile(lengths, 1)\n",
    "perc_99 = np.percentile(lengths, 99)\n",
    "print('1% percentile:', perc_1)\n",
    "print('99% percentile:', perc_99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews before removing outliers:  25001\n",
      "Number of reviews after removing outliers:  24532\n",
      "Mean length: 234.63027881950106\n"
     ]
    }
   ],
   "source": [
    "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
    "for i, review in enumerate(reviews_ints):\n",
    "    \n",
    "    if len(review) > perc_99 or len(review) < perc_1:\n",
    "        del reviews_ints[i]\n",
    "        del encoded_labels[i]\n",
    "        \n",
    "print('Number of reviews after removing outliers: ', len(reviews_ints))\n",
    "print('Mean length:', np.mean(list(map(f, reviews_ints))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4  \n",
    "Padding and truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_pad(review, seq_length, token):\n",
    "    \n",
    "    pad = [token for i in range(seq_length - len(review))]\n",
    "    # Add list of [token, ... , token] in the beginning\n",
    "    review[:0] = pad\n",
    "    \n",
    "    return review\n",
    "    \n",
    "    \n",
    "def pad_features(reviews_ints, seq_length, token):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    \n",
    "    features = list()\n",
    "    \n",
    "    for review in reviews_ints:\n",
    "        \n",
    "        if len(review) < seq_length:\n",
    "            review = left_pad(review, seq_length, token)\n",
    "            \n",
    "        else:\n",
    "            review = review[:seq_length]\n",
    "            \n",
    "        features.append(review)\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 13, 21, 22, 23, 24, 10, 25, 26, 27, 28, 29, 30, 31, 1, 2, 32, 33, 3, 34, 35, 29, 36, 37, 3, 21, 10, 38, 29, 39, 40, 10, 41, 42, 43, 44, 45, 46, 47, 48, 49, 21, 50, 10, 51, 52, 10, 53, 54, 55, 56, 28, 52, 10, 57, 58, 59, 60, 48, 42, 61, 58, 62, 10, 63, 24, 64, 4, 65, 66, 67, 29, 68, 69, 10, 18, 58, 70, 71, 9, 2, 4, 72, 73, 74, 58, 75, 76, 29, 77, 78, 52, 79, 21, 65, 80, 29, 1, 2, 58, 81, 31, 82, 83, 52, 22, 84, 85, 31, 1, 2, 3, 86, 87, 88, 4, 89, 31, 7, 90, 91], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 92, 52, 4, 93, 43, 94, 95, 96, 97, 4, 98, 99, 100, 101, 4, 102, 103, 31, 3, 4, 104, 105, 52, 106, 6, 4, 107, 108, 109, 3, 110, 111, 112, 113, 114, 115, 116, 10, 117, 118, 52, 7, 32, 119, 120, 7, 121, 106, 10, 53, 12, 101, 122, 123, 124, 125, 126, 7, 127, 128, 129, 130, 131, 132, 133, 10, 134, 135, 136, 110, 129, 10, 137, 138, 139, 140, 141, 142, 143, 29, 4, 144, 145, 146, 4, 147, 148, 7, 32, 149, 37, 150, 151, 85, 101, 14, 152, 153, 116, 154, 155, 156, 157, 154, 158, 159, 160, 60, 161, 162, 44, 136, 163, 164], [165, 166, 167, 13, 168, 169, 170, 94, 171, 112, 172, 97, 23, 173, 174, 4, 175, 29, 176, 132, 146, 10, 177, 31, 178, 179, 180, 181, 43, 182, 183, 133, 184, 29, 18, 185, 166, 186, 97, 10, 187, 188, 189, 85, 52, 10, 190, 13, 127, 4, 191, 192, 193, 194, 17, 195, 20, 13, 196, 10, 197, 146, 198, 199, 200, 29, 201, 202, 10, 203, 204, 166, 194, 205, 206, 207, 136, 208, 29, 209, 210, 146, 10, 211, 212, 212, 173, 88, 205, 150, 178, 213, 4, 214, 29, 215, 146, 10, 211, 97, 4, 216, 217, 10, 218, 150, 179, 219, 133, 4, 220, 10, 221, 222, 4, 223, 224, 146, 10, 225, 4, 226, 60, 183, 150, 179, 227, 29, 45, 88, 7, 32, 228, 29, 136, 190, 31, 3, 229, 230, 32, 231, 212, 212, 232, 233, 43, 234, 43, 158, 13, 230, 235, 4, 236, 93, 43, 94, 183, 24, 10, 237, 238, 239, 29, 140, 4, 214, 101, 4, 240, 241, 242, 243, 29, 45, 205, 244, 44, 215, 24, 10, 211, 97, 245, 246, 217, 10, 218, 205, 230, 247, 244, 44, 248, 88, 244, 249, 101, 4], [347, 99, 13, 4, 348, 349, 350, 351, 3, 352, 210, 101, 330, 353, 20, 354, 29, 236, 355, 356, 357, 358, 359, 43, 3, 360, 361, 4, 362, 52, 363, 32, 29, 256, 364, 24, 365, 52, 7, 301, 366, 29, 10, 367, 13, 4, 368, 369, 146, 370, 3, 357, 371, 372, 373, 374, 284, 375, 10, 350, 376, 377, 129, 13, 378, 173, 379, 380, 10, 351, 3, 381, 382, 116, 10, 383, 384, 385, 386, 387, 256, 388, 389, 32, 390, 391, 392, 291, 393, 394, 43, 395, 10, 396, 397, 100, 101, 398, 399, 206, 175, 29, 400, 10, 330, 401, 402, 146, 4, 403, 351, 404, 146, 112, 405, 406, 173, 193, 126, 256, 407, 385, 408, 409, 112, 410, 411, 24, 10, 412, 413, 414, 52, 10, 351, 415, 7, 416, 111, 10, 417, 253, 7, 418, 29, 10, 419, 46, 420, 24, 10, 421, 52, 10, 422, 423, 101, 380, 24, 424, 425, 426, 427, 24, 328, 428, 429, 430, 129, 431, 10, 432, 433, 97, 10, 434, 32, 13, 206, 435, 176, 101, 12, 436, 437, 100, 212, 212, 369, 438, 439, 10, 440, 441, 442, 347, 342, 443, 444, 29], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 651, 429, 617, 116, 275, 276, 277, 468, 652, 653, 654, 58, 464, 655, 163, 60, 306, 547, 24, 656, 657, 292, 443, 29, 658, 10, 659, 146, 660, 3, 4, 72, 13, 152, 13, 550, 24, 322, 323, 10, 661, 146, 662, 3, 369, 663, 266, 301, 664, 52, 301, 4, 665, 666, 100, 256, 667, 60, 301, 668, 10, 669, 52, 264, 230, 670, 671, 58, 75, 4, 669, 244, 549, 463, 672, 673, 674, 243, 4, 675, 133, 10, 676, 677, 678, 327, 3, 679, 76, 128, 13, 4, 680, 681, 43, 249, 29, 682, 10, 683, 256, 504, 3, 251, 684, 37, 685, 10, 686, 103, 60, 10, 103, 253, 10, 190, 687, 4, 688, 689, 292, 55, 12, 690, 552, 97, 10, 691, 103, 60, 10, 388, 692, 693, 694, 78, 695, 342, 696, 545, 149, 697, 12, 58, 45, 7, 64, 3, 698, 699], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 342, 343, 700, 329, 58, 701, 91, 702, 22, 703, 146, 9, 704, 705, 146, 10, 706, 52, 10, 707, 708, 342, 709, 710, 29, 510, 52, 711, 61, 712, 713, 10, 714, 101, 284, 707, 93, 131, 10, 715, 547, 716, 717, 13, 301, 718, 10, 719, 9, 720, 7, 499, 721, 722, 464, 171, 10, 723, 43, 724, 88, 244, 725, 133, 10, 719, 58, 127, 334, 91, 335, 212, 212, 173, 499, 7, 464, 171, 10, 726, 127, 727, 43, 449, 10, 728, 24, 306, 101, 244, 729, 251, 730, 52, 256, 731, 732, 60, 733, 60, 734, 52, 735, 60, 256, 736, 737, 37, 52, 738, 166, 550, 739, 244, 174, 740, 28, 244, 449, 24, 306, 101, 10, 741, 212, 212, 58, 449, 742, 24, 342, 696, 173, 334, 91, 743, 7, 449, 744, 97, 112, 618, 465, 745, 97, 746], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 342, 3, 747, 10, 188, 748, 343, 749, 10, 233, 750, 577, 751, 752, 7, 753, 297, 338, 4, 754, 755, 52, 165, 756, 455, 757, 758, 759, 760, 4, 754, 755, 52, 761, 119, 166, 762, 760, 4, 754, 755, 52, 763, 150, 764, 82, 52, 10, 765, 766, 767, 173, 768, 342, 343, 3, 721, 769, 24, 4, 770, 82, 771, 292, 297, 60, 29, 772, 31, 129, 24, 4, 92, 17, 14, 52, 10, 188, 773, 774, 775, 52, 776, 3, 777, 778, 751, 297, 10, 779, 780, 173, 751, 297, 781, 491, 22, 544, 782, 3, 31, 233, 135, 464, 783, 784, 739, 24, 10, 27, 58, 306, 232, 13, 4, 723, 60, 785, 297, 465, 34, 13, 4, 27], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 786, 787, 58, 335, 342, 3, 788, 29, 136, 112, 789, 343, 173, 790, 206, 135, 464, 791, 100, 792, 9, 10, 793, 465, 189, 499, 794, 48, 795, 100, 60, 297, 796, 460, 10, 103, 587, 60, 797, 643, 449, 798, 342, 92, 3, 128, 799, 29, 796, 10, 800, 52, 4, 801, 802, 449, 803, 10, 804, 532, 178, 128, 805, 757, 805, 44, 150, 796, 388, 189, 127, 806, 524, 60, 807, 808, 61, 10, 138, 3, 388, 189, 809, 58, 810, 219, 4, 811, 12, 127, 812, 47, 342, 343, 10, 813, 178, 798, 173, 757, 34, 52, 31, 814, 815, 816, 817, 44, 150, 661, 10, 544, 818, 58, 467, 449, 819, 820, 60, 284, 821, 822, 60, 823, 103, 824, 342, 449, 4, 825, 52, 826, 60, 58, 75, 122, 827, 828, 256, 491, 58, 85, 829, 43, 549, 206, 830, 831, 52, 342, 3, 722, 832], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 342, 3, 297, 10, 833, 232, 233, 343, 7, 449, 34, 834, 321, 37, 188, 52, 256, 835, 60, 466, 219, 4, 311, 31, 449, 836, 837, 276, 277, 500, 10, 696, 712, 3, 20, 4, 679, 439, 838, 708, 524, 178, 14, 839, 31, 499, 464, 171, 840, 100, 4, 640, 251, 60, 14, 547, 31, 499, 841, 464, 171, 580, 29, 140, 10, 842, 29, 248, 465, 173, 55, 24, 55, 342, 3, 843, 10, 844, 29, 845, 60, 45, 7, 10, 617, 449, 152, 846, 233, 735, 182, 4, 152, 847, 217, 256, 848, 849, 29, 850, 29, 10, 109, 453, 277, 449, 10, 468, 851, 24, 10, 696, 173, 852, 60, 286, 853, 854, 48, 855, 722], [61, 58, 449, 501, 22, 856, 857, 28, 593, 29, 10, 858, 29, 45, 859, 7, 449, 78, 52, 82, 835, 58, 860, 101, 22, 856, 173, 342, 449, 10, 544, 78, 861, 862, 100, 52, 623, 472, 58, 219, 174, 163, 859, 238, 127, 863, 60, 58, 499, 464, 864, 100, 10, 865, 52, 22, 19, 217, 7, 88, 4, 866, 867, 60, 868, 648, 869, 52, 32, 870, 60, 871, 872, 873, 874, 3, 78, 52, 22, 675, 875, 173, 859, 3, 116, 86, 10, 876, 869, 52, 781, 52, 256, 877, 24, 10, 878, 879, 52, 880, 881, 874, 882, 559, 4, 814, 883, 884, 885, 24, 29, 10, 886, 52, 4, 887, 888, 116, 10, 889, 890, 891, 116, 281, 892, 877, 306, 893, 306, 894, 895, 10, 343, 896, 94, 122, 897, 898, 122, 899, 60, 3, 900, 24, 901, 902, 342, 343, 879, 44, 136, 468, 903, 13, 904, 24, 905, 340, 112, 906, 907, 52, 138, 29, 908, 4, 251, 909, 910, 52, 911, 60, 912, 173, 873, 874, 3, 122, 880, 826, 10, 343, 3, 868, 607, 60, 505, 173, 913, 31, 58, 914, 219, 122, 307, 101, 166, 915, 97, 456]]\n"
     ]
    }
   ],
   "source": [
    "features = pad_features(reviews_ints, seq_length=seq_length, token = vocab_to_int['\\n'])\n",
    "\n",
    "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "print(features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (24532, 200)\n",
      "Target shape: (24532,)\n"
     ]
    }
   ],
   "source": [
    "features = np.array(features)\n",
    "encoded_labels = np.array(encoded_labels)\n",
    "print(f'Data shape: {features.shape}\\nTarget shape: {encoded_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (19625, 200)\n",
      "Validation set shape: (2453, 200)\n",
      "Test set shape: (2454, 200)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "train_len = int(features.shape[0] * split_frac)\n",
    "valid_len = (features.shape[0] - train_len) // 2\n",
    "test_len  = features.shape[0] - train_len - valid_len\n",
    "\n",
    "train_features = features[:train_len]\n",
    "train_labels = encoded_labels[:train_len]\n",
    "\n",
    "valid_features = features[train_len : train_len + valid_len]\n",
    "valid_labels = encoded_labels[train_len : train_len + valid_len]\n",
    "\n",
    "test_features = features[train_len + valid_len :]\n",
    "test_labels = encoded_labels[train_len + valid_len :] \n",
    "\n",
    "print(f'Training set shape: {train_features.shape}\\nValidation set shape: {valid_features.shape}\\nTest set shape: {test_features.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_features), torch.from_numpy(train_labels))\n",
    "valid_data = TensorDataset(torch.from_numpy(valid_features), torch.from_numpy(valid_labels))\n",
    "test_data = TensorDataset(torch.from_numpy(test_features), torch.from_numpy(test_labels))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# Shuffle data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 200])\n",
      "Sample input: \n",
      " tensor([[  342,  4256,    94,  ...,    13,  1911, 20511],\n",
      "        [    0,     0,     0,  ...,   696, 34770,   544],\n",
      "        [  282,   524,   449,  ..., 54344,     3,  2936],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ..., 39083,    32,   835],\n",
      "        [    0,     0,     0,  ...,    62, 12759,   540],\n",
      "        [    0,     0,     0,  ...,   944,    78,  3511]], dtype=torch.int32)\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU GeForce MX250\n"
     ]
    }
   ],
   "source": [
    "gpu_use = torch.cuda.is_available()\n",
    "\n",
    "if gpu_use is True:\n",
    "    print(f'Using GPU ({torch.cuda.get_device_name()})')\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from models import SentimentRNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
